{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a Simple LLM Application with LCEL\n",
    "In this quickstart we'll show you how to build a simple LLM application with LangChain. This application will translate text from English into another language. This is a relatively simple LLM application - it's just a single LLM call plus some prompting. Still, this is a great way to get started with LangChain - a lot of features can be built with just some prompting and an LLM call!\n",
    "\n",
    "After seeing this video, you'll have a high level overview of:\n",
    "\n",
    "- Using language models\n",
    "\n",
    "- Using PromptTemplates and OutputParsers\n",
    "\n",
    "- Using LangChain Expression Language (LCEL) to chain components together\n",
    "\n",
    "- Debugging and tracing your application using LangSmith\n",
    "\n",
    "- Deploying your application with LangServe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'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'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Open AI API Key and Open Source models--Llama3,Gemma2,mistral--Groq\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "groq_api_key=os.getenv(\"GROQ_API_KEY\")\n",
    "groq_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain_groq\n",
      "  Downloading langchain_groq-0.3.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.49 in d:\\python_env\\langchain\\venv\\lib\\site-packages (from langchain_groq) (0.3.61)\n",
      "Collecting groq<1,>=0.4.1 (from langchain_groq)\n",
      "  Downloading groq-0.26.0-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in d:\\python_env\\langchain\\venv\\lib\\site-packages (from groq<1,>=0.4.1->langchain_groq) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in d:\\python_env\\langchain\\venv\\lib\\site-packages (from groq<1,>=0.4.1->langchain_groq) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in d:\\python_env\\langchain\\venv\\lib\\site-packages (from groq<1,>=0.4.1->langchain_groq) (0.28.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in d:\\python_env\\langchain\\venv\\lib\\site-packages (from groq<1,>=0.4.1->langchain_groq) (2.11.5)\n",
      "Requirement already satisfied: sniffio in d:\\python_env\\langchain\\venv\\lib\\site-packages (from groq<1,>=0.4.1->langchain_groq) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.10 in d:\\python_env\\langchain\\venv\\lib\\site-packages (from groq<1,>=0.4.1->langchain_groq) (4.13.2)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in d:\\python_env\\langchain\\venv\\lib\\site-packages (from anyio<5,>=3.5.0->groq<1,>=0.4.1->langchain_groq) (1.3.0)\n",
      "Requirement already satisfied: idna>=2.8 in d:\\python_env\\langchain\\venv\\lib\\site-packages (from anyio<5,>=3.5.0->groq<1,>=0.4.1->langchain_groq) (3.10)\n",
      "Requirement already satisfied: certifi in d:\\python_env\\langchain\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain_groq) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\python_env\\langchain\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain_groq) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in d:\\python_env\\langchain\\venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain_groq) (0.16.0)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.126 in d:\\python_env\\langchain\\venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.49->langchain_groq) (0.3.42)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in d:\\python_env\\langchain\\venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.49->langchain_groq) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in d:\\python_env\\langchain\\venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.49->langchain_groq) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in d:\\python_env\\langchain\\venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.49->langchain_groq) (6.0.2)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in d:\\python_env\\langchain\\venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.49->langchain_groq) (24.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in d:\\python_env\\langchain\\venv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.49->langchain_groq) (3.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in d:\\python_env\\langchain\\venv\\lib\\site-packages (from langsmith<0.4,>=0.1.126->langchain-core<1.0.0,>=0.3.49->langchain_groq) (3.10.18)\n",
      "Requirement already satisfied: requests<3,>=2 in d:\\python_env\\langchain\\venv\\lib\\site-packages (from langsmith<0.4,>=0.1.126->langchain-core<1.0.0,>=0.3.49->langchain_groq) (2.32.3)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in d:\\python_env\\langchain\\venv\\lib\\site-packages (from langsmith<0.4,>=0.1.126->langchain-core<1.0.0,>=0.3.49->langchain_groq) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in d:\\python_env\\langchain\\venv\\lib\\site-packages (from langsmith<0.4,>=0.1.126->langchain-core<1.0.0,>=0.3.49->langchain_groq) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in d:\\python_env\\langchain\\venv\\lib\\site-packages (from pydantic<3,>=1.9.0->groq<1,>=0.4.1->langchain_groq) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in d:\\python_env\\langchain\\venv\\lib\\site-packages (from pydantic<3,>=1.9.0->groq<1,>=0.4.1->langchain_groq) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in d:\\python_env\\langchain\\venv\\lib\\site-packages (from pydantic<3,>=1.9.0->groq<1,>=0.4.1->langchain_groq) (0.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\python_env\\langchain\\venv\\lib\\site-packages (from requests<3,>=2->langsmith<0.4,>=0.1.126->langchain-core<1.0.0,>=0.3.49->langchain_groq) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\python_env\\langchain\\venv\\lib\\site-packages (from requests<3,>=2->langsmith<0.4,>=0.1.126->langchain-core<1.0.0,>=0.3.49->langchain_groq) (2.4.0)\n",
      "Downloading langchain_groq-0.3.2-py3-none-any.whl (15 kB)\n",
      "Downloading groq-0.26.0-py3-none-any.whl (129 kB)\n",
      "Installing collected packages: groq, langchain_groq\n",
      "\n",
      "   ---------------------------------------- 0/2 [groq]\n",
      "   ---------------------------------------- 0/2 [groq]\n",
      "   ---------------------------------------- 0/2 [groq]\n",
      "   ---------------------------------------- 0/2 [groq]\n",
      "   ---------------------------------------- 0/2 [groq]\n",
      "   ---------------------------------------- 0/2 [groq]\n",
      "   ---------------------------------------- 0/2 [groq]\n",
      "   ---------------------------------------- 0/2 [groq]\n",
      "   ---------------------------------------- 0/2 [groq]\n",
      "   ---------------------------------------- 0/2 [groq]\n",
      "   ---------------------------------------- 2/2 [langchain_groq]\n",
      "\n",
      "Successfully installed groq-0.26.0 langchain_groq-0.3.2\n"
     ]
    }
   ],
   "source": [
    "#!pip install langchain_groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x0000028A9FA5C280>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x0000028A9FA29720>, model_name='Gemma2-9b-It', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "model=ChatGroq(model=\"Gemma2-9b-It\",groq_api_key=groq_api_key)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Nietzsche\\'s famous proclamation, \"God is dead,\" is a complex and often misinterpreted statement. It\\'s not meant to be taken literally as a statement about the physical death of a deity. \\n\\nHere\\'s a breakdown of what Nietzsche meant:\\n\\n**1. The Decline of Religious Belief:**\\n\\nNietzsche lived in a time when traditional religious authority was waning in Europe. Enlightenment ideas, scientific discoveries, and social changes were challenging the foundations of Christian morality and belief. Nietzsche saw this decline as a profound shift in human history, a \"death\" of the old ways of thinking.\\n\\n**2. The Loss of Meaning and Values:**\\n\\nFor Nietzsche, God wasn\\'t just a figure of faith, but also a source of meaning and moral values. With God\\'s \"death,\" traditional sources of morality and purpose were lost. This created a sense of nihilism, a feeling of meaninglessness and emptiness.\\n\\n**3. The Need for Revaluation:**\\n\\nNietzsche believed that the \"death of God\" wasn\\'t something to be mourned but rather an opportunity. He called for a \"revaluation of all values,\" urging humans to create their own meaning and morality in the absence of divine guidance.\\n\\n**4. The Will to Power:**\\n\\nCentral to Nietzsche\\'s philosophy is the concept of the \"will to power,\" a fundamental drive within all living beings to grow, overcome obstacles, and assert themselves. He saw the \"death of God\" as liberating humanity from the constraints of traditional morality and allowing individuals to embrace their will to power.\\n\\n**Important Considerations:**\\n\\n* Nietzsche wasn\\'t advocating for atheism in the traditional sense. He was more concerned with the consequences of losing faith in absolute truth and morality.\\n* His statement is often misconstrued as celebrating the demise of religion. In reality, he saw the \"death of God\" as a tragic and challenging event that required humans to confront the fundamental questions of existence.\\n* Nietzsche\\'s philosophy is complex and multifaceted. \"God is dead\" is just one provocative statement within a larger body of work that explores themes of nihilism, morality, and the human condition.\\n\\nUnderstanding Nietzsche\\'s \"God is dead\" requires going beyond a simple interpretation and engaging with his broader philosophical arguments.\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response= model.invoke(\"What Nietzsche meant by God is dead?\")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain_core in e:\\udemy final\\langchain\\venv\\lib\\site-packages (0.2.10)\n",
      "Requirement already satisfied: PyYAML>=5.3 in e:\\udemy final\\langchain\\venv\\lib\\site-packages (from langchain_core) (6.0.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in e:\\udemy final\\langchain\\venv\\lib\\site-packages (from langchain_core) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.75 in e:\\udemy final\\langchain\\venv\\lib\\site-packages (from langchain_core) (0.1.77)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in e:\\udemy final\\langchain\\venv\\lib\\site-packages (from langchain_core) (24.1)\n",
      "Requirement already satisfied: pydantic<3,>=1 in e:\\udemy final\\langchain\\venv\\lib\\site-packages (from langchain_core) (2.7.4)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in e:\\udemy final\\langchain\\venv\\lib\\site-packages (from langchain_core) (8.4.1)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in e:\\udemy final\\langchain\\venv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain_core) (3.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in e:\\udemy final\\langchain\\venv\\lib\\site-packages (from langsmith<0.2.0,>=0.1.75->langchain_core) (3.10.5)\n",
      "Requirement already satisfied: requests<3,>=2 in e:\\udemy final\\langchain\\venv\\lib\\site-packages (from langsmith<0.2.0,>=0.1.75->langchain_core) (2.31.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in e:\\udemy final\\langchain\\venv\\lib\\site-packages (from pydantic<3,>=1->langchain_core) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.4 in e:\\udemy final\\langchain\\venv\\lib\\site-packages (from pydantic<3,>=1->langchain_core) (2.18.4)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in e:\\udemy final\\langchain\\venv\\lib\\site-packages (from pydantic<3,>=1->langchain_core) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in e:\\udemy final\\langchain\\venv\\lib\\site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain_core) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\udemy final\\langchain\\venv\\lib\\site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain_core) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in e:\\udemy final\\langchain\\venv\\lib\\site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain_core) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\udemy final\\langchain\\venv\\lib\\site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain_core) (2024.6.2)\n"
     ]
    }
   ],
   "source": [
    "#!pip install langchain_core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why do programmers prefer dark mode? \n",
      "\n",
      "Because light attracts bugs! üêû  üòÑ  \n",
      "\n",
      "\n",
      "Let me know if you'd like to hear another one! \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"Tell me a joke about {topic}\")\n",
    "model=ChatGroq(model=\"Gemma2-9b-It\")\n",
    "\n",
    "# Pipe operator (|) chains components\n",
    "chain = prompt | model\n",
    "\n",
    "response = chain.invoke({\"topic\": \"programming\"})\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why did the AI cross the road? \n",
      "\n",
      "Because it was programmed to!  üêîü§ñüòÇ \n",
      "\n",
      "\n",
      "Let me know if you'd like to hear another one!  üòÑ  \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "chain = prompt | model | StrOutputParser()  # Converts to clean text\n",
    "response = chain.invoke({\"topic\": \"AI\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage,SystemMessage\n",
    "\n",
    "messages=[\n",
    "    SystemMessage(content=\"Translate the following from English to Hindi\"),\n",
    "    HumanMessage(content=\"Hello How are you?\")\n",
    "]\n",
    "\n",
    "result=model.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='‡§®‡§Æ‡§∏‡•ç‡§§‡•á, ‡§Ü‡§™ ‡§ï‡•à‡§∏‡•á ‡§π‡•à‡§Ç? (Namaste, aap kaise hain?) \\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 22, 'prompt_tokens': 21, 'total_tokens': 43, 'completion_time': 0.04, 'prompt_time': 0.003614227, 'queue_time': 0.245624951, 'total_time': 0.043614227}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--ec9589ce-2cfb-478c-b107-1bf8e34c908c-0', usage_metadata={'input_tokens': 21, 'output_tokens': 22, 'total_tokens': 43})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'‡§®‡§Æ‡§∏‡•ç‡§§‡•á, ‡§Ü‡§™ ‡§ï‡•à‡§∏‡•á ‡§π‡•à‡§Ç? (Namaste, aap kaise hain?) \\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "parser=StrOutputParser()\n",
    "parser.invoke(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'‡§®‡§Æ‡§∏‡•ç‡§§‡•á, ‡§Ü‡§™ ‡§ï‡•à‡§∏‡•á ‡§π‡•à‡§Ç?  (Namaste, aap kaise hain?) \\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Using LCEL- chain the components\n",
    "chain=model|parser\n",
    "chain.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "generic_template = \"Translate the following in {language}.\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "        [(\"system\", generic_template),\n",
    "         (\"user\",\" {text}\")\n",
    "         ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "result=prompt.invoke({\"language\":\"Hindi\",\"text\":\"Hello\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='Translate the following in Hindi.', additional_kwargs={}, response_metadata={}), HumanMessage(content=' Hello', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='Translate the following in Hindi.', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content=' Hello', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.to_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'‡§®‡§Æ‡§∏‡•ç‡§§‡•á (Namaste) \\n'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Chaining together components with LCEL\n",
    "chain=prompt|model|parser\n",
    "chain.invoke({\"language\":\"Hindi\",\"text\":\"Hello\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
