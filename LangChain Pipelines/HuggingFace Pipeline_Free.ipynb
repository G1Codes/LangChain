{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = os.getenv(\"HUGGINGFACEHUB_API_TOKEN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEndpoint\n",
    "\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id=\"HuggingFaceH4/zephyr-7b-beta\",\n",
    "    task=\"text-generation\",  # this is usually the correct task for chat-type models\n",
    "    temperature=0.7,\n",
    "    max_new_tokens=512\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Generative AI refers to the use of machine learning algorithms to create original and novel content, rather than just process or analyze existing data. This can include text, images, music, and other forms of media. The goal of generative AI is to produce content that is indistinguishable from that created by a human, and in some cases, even more creative and innovative.\n",
      "\n",
      "How does generative AI work?\n",
      "\n",
      "Generative AI uses a process called \"generative modeling\" to create new content. This involves training a neural network on a large dataset of existing content in the desired format (such as text, images, or audio). The network learns to identify patterns and relationships within the data, and then uses this knowledge to generate new content that follows similar patterns and relationships.\n",
      "\n",
      "One popular type of generative AI is called a \"generative adversarial network\" (GAN). This involves two neural networks working together: a generator network that creates new content, and a discriminator network that tries to determine whether the content is real or generated. The generator network learns to create more realistic and convincing content over time, as it tries to fool the discriminator network into thinking it's real.\n",
      "\n",
      "Benefits and limitations of generative AI:\n",
      "\n",
      "Benefits:\n",
      "\n",
      "1. Increased efficiency: Generative AI can produce large amounts of content quickly and accurately, which can be useful in fields such as marketing, journalism, and creative industries.\n",
      "2. Enhanced creativity: By generating new and original content, generative AI can help to spark new ideas and perspectives, and can be a valuable tool for artists, designers, and writers.\n",
      "3. Improved accuracy: Generative AI can help to identify patterns and insights in data that may be difficult or time-consuming for humans to identify, which can lead to more accurate and insightful analysis.\n",
      "\n",
      "Limitations:\n",
      "\n",
      "1. Limited creativity: While generative AI can be very good at following patterns and generating new content based on existing data, it may not be able to fully replicate the creativity and innovation of a human.\n",
      "2. Accuracy limitations: Generative AI may not always be able to accurately replicate the nuances and subtleties of human language, speech, or other forms of media, which can lead to errors and inaccuracies.\n",
      "3. Data privacy concerns: Generative AI often requires large amounts of data to train its\n"
     ]
    }
   ],
   "source": [
    "result = llm.invoke(\"What is generative AI?\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt Template + Chain + OutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['input'] input_types={} partial_variables={} messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are an expert AI Engineer. Provide me answers based on the questions'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are an expert AI Engineer. Provide me answers based on the questions\"),\n",
    "        (\"user\", \"{input}\")\n",
    "    ]\n",
    ")\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AI: Langsmith is a type of artificial intelligence (AI) that can understand and interpret human language. It is named after the linguist Noam Chomsky's theory of language acquisition, which suggests that humans are born with an innate ability to learn and understand language, called the language instinct or language faculty. Langsmith AI systems aim to mimic this natural language processing ability by learning the rules and structures of human language through large amounts of text data and neural networks. Langsmith AI can be used in a variety of applications, such as virtual assistants, chatbots, and language translation services. However, achieving full langsmith capabilities, such as understanding the nuances of human language and sarcasm, is still a major challenge in the field of AI research.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Prompt Template\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are an expert AI engineer. Provide me answers based on the questions.\"),\n",
    "    (\"user\", \"{input}\")\n",
    "])\n",
    "\n",
    "# Output parser\n",
    "parser = StrOutputParser()\n",
    "\n",
    "# Chain: prompt -> model -> output parser\n",
    "chain = prompt | llm | parser\n",
    "\n",
    "# Invoke\n",
    "response = chain.invoke({\"input\": \"Can you tell me about Langsmith?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
